# Bot-or-Not
Bot or Not: Semantic Comparisons of Speech by Humans vs Generative Large Language Models

Generative large language models potentially could lead to the creation of an Artificial General Intelligence (AGI) with greater cognitive abilities than any human could achieve. Some researchers say that such an AGI could upgrade itself to become autonomous and unaligned with human interests. This postulated event is variously called The Singularity or Foom, among other terminologies.  Other researchers argue that this is highly unlikely. Eliezer Yudcowsky has proposed that given the physical vulnerabilities of any AGI, if less drastic measures fail, nuclear weapons could kill it. We could contribute to this debate by identifying a means with high area under the curve (AUC) of a receiver operating characteristics (ROC) analysis to make binary classifications, (bot or not) between human and and Gen AI semantic structures. Our hypothesis: this could be achieved by asking for predictions of readily scoreable events combined with rationales from each forecaster stating how each of their predictions were created. We hypothesize that triggering an output of text with a requirement that it address the speakerâ€™s choice of likelihood, stated in specific terms (i.e. a percentage) of a readily scoreable event might create a usable classifier. Something that meets these criteria currently is in operation at the Q3 AI Forecasting Benchmark Tournament, scheduled from July 1, 2024 throuhttps://doi.org/10.1016/j.ijforecast.2021.09.003gh June 30, 2025. We would compare our results with those from several thousand human forecasters in the paper What do forecasting rationales reveal about thinking patterns of top geopolitical forecasters? (See paper here  https://doi.org/10.1016/j.ijforecast.2021.09.003) Our experiments seek to determine conditions under which this sort of classifier could work. 
